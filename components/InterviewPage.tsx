/**
 * ë©´ì ‘ ì§„í–‰ í˜ì´ì§€ ì»´í¬ë„ŒíŠ¸ (ë¦¬íŒ©í† ë§)
 */
'use client';

import React, { useState, useRef, useEffect, useCallback } from 'react';
import CountdownTimer from './CountdownTimer';
import AudioVisualizer from './AudioVisualizer';
import { apiClient } from '@/lib/api-client';

interface InterviewPageProps {
  sessionId: number;
  initialQuestionText: string;
  initialQuestionAudioUrl: string;
  onInterviewComplete: (sessionId: number) => void;
}

// ë©´ì ‘ ìƒíƒœ íƒ€ì… ì •ì˜
type InterviewState = 'listening' | 'recording' | 'processing' | 'waiting_next';

export default function InterviewPage({
  sessionId,
  initialQuestionText,
  initialQuestionAudioUrl,
  onInterviewComplete,
}: InterviewPageProps) {
  // ì§ˆë¬¸ ì •ë³´
  const [questionText, setQuestionText] = useState(initialQuestionText);
  const [questionAudioUrl, setQuestionAudioUrl] = useState(initialQuestionAudioUrl);
  const [turnNumber, setTurnNumber] = useState(1);
  
  // ìƒíƒœ ê´€ë¦¬ (ëª…í™•í•œ ìƒíƒœ êµ¬ë¶„)
  const [interviewState, setInterviewState] = useState<InterviewState>('listening');
  
  // ë…¹ìŒ ê´€ë ¨
  const audioRef = useRef<HTMLAudioElement | null>(null);
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const mediaStreamRef = useRef<MediaStream | null>(null);
  const audioChunksRef = useRef<Blob[]>([]);
  const recordedAudioRef = useRef<Blob | null>(null);
  
  // í´ë°±(Fallback) ìƒíƒœ: ìë™ ì¬ìƒ ì‹¤íŒ¨ ì‹œ ìˆ˜ë™ ë²„íŠ¼ í‘œì‹œ
  const [showPlayButton, setShowPlayButton] = useState(false);

  /**
   * ê²¬ê³ í•œ ì˜¤ë””ì˜¤ ì¬ìƒ ë¡œì§
   * questionAudioUrlì´ ë³€ê²½ë  ë•Œë§Œ ì‹¤í–‰
   */
  useEffect(() => {
    // ë””ë²„ê·¸ ë¡œê¹… 1: URL í™•ì¸
    console.log('ğŸµ [TTS DEBUG] Current Audio URL:', questionAudioUrl);
    console.log('ğŸµ [TTS DEBUG] URL Type:', typeof questionAudioUrl);
    console.log('ğŸµ [TTS DEBUG] URL Length:', questionAudioUrl?.length);
    console.log('ğŸ“Š [TTS DEBUG] Interview State:', interviewState);

    // URLì´ ì—†ê±°ë‚˜ ë¹ˆ ë¬¸ìì—´ì´ë©´ ì¢…ë£Œ
    if (!questionAudioUrl || questionAudioUrl.trim().length === 0) {
      console.warn('âš ï¸ [TTS DEBUG] ìœ íš¨í•˜ì§€ ì•Šì€ ì˜¤ë””ì˜¤ URL');
      return;
    }

    // 'listening' ìƒíƒœê°€ ì•„ë‹ˆë©´ ì¬ìƒí•˜ì§€ ì•ŠìŒ
    if (interviewState !== 'listening') {
      console.log('â¸ï¸ [TTS DEBUG] Not in listening state, skipping playback');
      return;
    }

    // audioRefê°€ ì—†ìœ¼ë©´ ì¢…ë£Œ
    if (!audioRef.current) {
      console.error('âŒ [TTS DEBUG] Audio element ref is null');
      return;
    }

    // ì¬ìƒ ì‹œë„ í•¨ìˆ˜
    const attemptPlay = async () => {
      try {
        console.log('ğŸ”„ [TTS DEBUG] Loading audio...');
        audioRef.current!.load();

        console.log('â–¶ï¸ [TTS DEBUG] Attempting to play audio...');
        await audioRef.current!.play();

        console.log('âœ… [TTS DEBUG] Audio playback successful!');
        setShowPlayButton(false); // ì„±ê³µ ì‹œ ë²„íŠ¼ ìˆ¨ê¹€
      } catch (error: any) {
        console.error('âŒ [TTS DEBUG] Audio playback failed:', error);
        console.error('Error name:', error.name);
        console.error('Error message:', error.message);

        // ë¸Œë¼ìš°ì € ìë™ ì¬ìƒ ì •ì±…ìœ¼ë¡œ ì°¨ë‹¨ëœ ê²½ìš°
        if (error.name === 'NotAllowedError' || error.name === 'NotSupportedError') {
          console.warn('âš ï¸ [TTS DEBUG] Blocked by browser autoplay policy');
          setShowPlayButton(true); // ìˆ˜ë™ ì¬ìƒ ë²„íŠ¼ í‘œì‹œ
        } else {
          console.error('âš ï¸ [TTS DEBUG] Other audio error');
          setShowPlayButton(true);
        }
      }
    };

    // ì•½ê°„ì˜ ì§€ì—° í›„ ì¬ìƒ ì‹œë„ (DOM ì¤€ë¹„ ëŒ€ê¸°)
    const timer = setTimeout(attemptPlay, 100);

    return () => clearTimeout(timer);
  }, [questionAudioUrl, interviewState]);


  /**
   * ìˆ˜ë™ ì¬ìƒ ë²„íŠ¼ í´ë¦­ (í´ë°±)
   */
  const handleManualPlay = async () => {
    console.log('ğŸ–±ï¸ [TTS DEBUG] User clicked manual play button');
    
    if (!audioRef.current) {
      console.error('âŒ [TTS DEBUG] Audio ref is null on manual play');
      return;
    }

    try {
      console.log('â–¶ï¸ [TTS DEBUG] Manual play attempt...');
      await audioRef.current.play();
      console.log('âœ… [TTS DEBUG] Manual play successful!');
      setShowPlayButton(false); // ì¬ìƒ ì„±ê³µ ì‹œ ë²„íŠ¼ ìˆ¨ê¹€
    } catch (error: any) {
      console.error('âŒ [TTS DEBUG] Manual play failed:', error);
      alert('ì˜¤ë””ì˜¤ ì¬ìƒì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë¸Œë¼ìš°ì € ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.');
    }
  };

  /**
   * ì§ˆë¬¸ ì˜¤ë””ì˜¤ ì¬ìƒ ì™„ë£Œ í•¸ë“¤ëŸ¬
   */
  const handleQuestionAudioEnded = () => {
    console.log('ì§ˆë¬¸ ì˜¤ë””ì˜¤ ì¬ìƒ ì™„ë£Œ');
    startRecording();
  };

  /**
   * ë…¹ìŒ ì‹œì‘
   */
  const startRecording = async () => {
    try {
      console.log('ë…¹ìŒ ì‹œì‘ ì‹œë„...');
      
      // ê¸°ì¡´ ìŠ¤íŠ¸ë¦¼ ì •ë¦¬
      cleanupMediaStream();

      const stream = await navigator.mediaDevices.getUserMedia({ 
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true,
        } 
      });

      mediaStreamRef.current = stream;
      
      // MediaRecorder ìƒì„±
      const mediaRecorder = new MediaRecorder(stream, {
        mimeType: 'audio/webm',
      });

      mediaRecorderRef.current = mediaRecorder;
      audioChunksRef.current = [];

      mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          audioChunksRef.current.push(event.data);
        }
      };

      mediaRecorder.onstop = () => {
        console.log('ë…¹ìŒ ì •ì§€ë¨, ì˜¤ë””ì˜¤ ìƒì„± ì¤‘...');
        const audioBlob = new Blob(audioChunksRef.current, { type: 'audio/webm' });
        recordedAudioRef.current = audioBlob;
        
        // ìŠ¤íŠ¸ë¦¼ ì •ë¦¬
        cleanupMediaStream();
        
        // ë‹¤ìŒ ì§ˆë¬¸ ëŒ€ê¸° ìƒíƒœë¡œ ì „í™˜
        setInterviewState('waiting_next');
      };

      mediaRecorder.onerror = (event: any) => {
        console.error('MediaRecorder ì—ëŸ¬:', event.error);
        cleanupMediaStream();
        alert('ë…¹ìŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.');
      };

      // ë…¹ìŒ ì‹œì‘
      mediaRecorder.start();
      setInterviewState('recording');
      console.log('ë…¹ìŒ ì‹œì‘ë¨');
      
    } catch (error) {
      console.error('ë…¹ìŒ ì‹œì‘ ì‹¤íŒ¨:', error);
      alert('ë§ˆì´í¬ ì ‘ê·¼ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤. ë¸Œë¼ìš°ì € ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.');
      cleanupMediaStream();
    }
  };

  /**
   * ë…¹ìŒ ì¤‘ì§€
   */
  const stopRecording = () => {
    if (mediaRecorderRef.current && mediaRecorderRef.current.state === 'recording') {
      console.log('ë…¹ìŒ ì¤‘ì§€ ì‹œë„...');
      mediaRecorderRef.current.stop();
      setInterviewState('waiting_next');
    }
  };

  /**
   * MediaStream ì •ë¦¬ (í¬íŠ¸ ì—°ê²° í•´ì œ ë¬¸ì œ í•´ê²°)
   */
  const cleanupMediaStream = () => {
    if (mediaStreamRef.current) {
      mediaStreamRef.current.getTracks().forEach((track) => {
        track.stop();
        track.enabled = false;
      });
      mediaStreamRef.current = null;
    }
    mediaRecorderRef.current = null;
  };

  /**
   * íƒ€ì´ë¨¸ ì™„ë£Œ í•¸ë“¤ëŸ¬ (60ì´ˆ ê²½ê³¼)
   */
  const handleCountdownComplete = () => {
    console.log('íƒ€ì´ë¨¸ ì¢…ë£Œ, ë…¹ìŒ ì¤‘ì§€');
    stopRecording();
  };

  /**
   * ë‹¤ìŒ ì§ˆë¬¸ ë²„íŠ¼ í´ë¦­ (ë‹µë³€ ì œì¶œ)
   */
  const handleNextQuestion = async () => {
    if (!recordedAudioRef.current) {
      alert('ë…¹ìŒëœ ë‹µë³€ì´ ì—†ìŠµë‹ˆë‹¤.');
      return;
    }

    setInterviewState('processing');

    try {
      const formData = new FormData();
      formData.append('sessionId', sessionId.toString());
      formData.append('turnNumber', turnNumber.toString());
      formData.append('audio', recordedAudioRef.current, `answer_${turnNumber}.webm`);

      const token = localStorage.getItem('token');

      const response = await fetch('/api/interview/answer', {
        method: 'POST',
        headers: {
          Authorization: `Bearer ${token}`,
        },
        body: formData,
      });

      const data = await response.json();

      // ë…¹ìŒëœ ì˜¤ë””ì˜¤ ì´ˆê¸°í™”
      recordedAudioRef.current = null;

      if (data.isCompleted) {
        // ë©´ì ‘ ì™„ë£Œ
        console.log('ë©´ì ‘ ì™„ë£Œ, ê²°ê³¼ í˜ì´ì§€ë¡œ ì´ë™');
        onInterviewComplete(sessionId);
      } else {
        // ë‹¤ìŒ ì§ˆë¬¸ìœ¼ë¡œ ì´ë™
        console.log('ë‹¤ìŒ ì§ˆë¬¸ ë¡œë“œ:', data.turnNumber);
        setQuestionText(data.questionText);
        setQuestionAudioUrl(data.questionAudioUrl);
        setTurnNumber(data.turnNumber);
        setInterviewState('listening');
      }
    } catch (error) {
      console.error('ë‹µë³€ ì œì¶œ ì‹¤íŒ¨:', error);
      alert('ë‹µë³€ ì œì¶œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.');
      setInterviewState('waiting_next');
    }
  };

  /**
   * ë©´ì ‘ ì¢…ë£Œ ë° ê²°ê³¼ ë³´ê¸° (ì–¸ì œë“  ê°€ëŠ¥)
   */
  const handleFinishAndViewResults = async () => {
    // ë‹µë³€ì´ í•˜ë‚˜ë„ ì—†ìœ¼ë©´ ì¢…ë£Œ ë¶ˆê°€
    if (turnNumber < 2) {
      alert('ìµœì†Œ 1ê°œ ì´ìƒì˜ ì§ˆë¬¸ì— ë‹µë³€í•´ì•¼ ê²°ê³¼ë¥¼ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.');
      return;
    }

    const confirmed = confirm(
      `í˜„ì¬ê¹Œì§€ì˜ ë‹µë³€ìœ¼ë¡œ í‰ê°€ë¥¼ ì§„í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ?\n\n` +
      `ë‹µë³€í•˜ì‹  ${turnNumber - 1}ê°œì˜ ì§ˆë¬¸ì— ëŒ€í•œ AI í”¼ë“œë°±ì„ ë°›ìœ¼ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.`
    );

    if (!confirmed) return;

    try {
      setInterviewState('processing');
      console.log('ğŸ”š ë©´ì ‘ ì¢…ë£Œ ë° í‰ê°€ ì‹œì‘...');

      const response = await apiClient.finishInterview(sessionId);

      console.log('âœ… í‰ê°€ ì™„ë£Œ:', response);

      // ì •ë¦¬ ë° ê²°ê³¼ í˜ì´ì§€ë¡œ ì´ë™
      cleanupMediaStream();
      onInterviewComplete(sessionId);
    } catch (error) {
      console.error('âŒ í‰ê°€ ì²˜ë¦¬ ì‹¤íŒ¨:', error);
      alert('í‰ê°€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.');
      setInterviewState('waiting_next');
    }
  };

  // ì»´í¬ë„ŒíŠ¸ ì–¸ë§ˆìš´íŠ¸ ì‹œ ì •ë¦¬
  useEffect(() => {
    return () => {
      cleanupMediaStream();
    };
  }, []);

  // ìƒíƒœë³„ UI ë©”ì‹œì§€
  const getStateMessage = () => {
    switch (interviewState) {
      case 'listening':
        return 'ğŸ§ ì§ˆë¬¸ì„ ë“£ê³  ìˆìŠµë‹ˆë‹¤...';
      case 'recording':
        return 'ğŸ¤ ë‹µë³€ì„ ë…¹ìŒ ì¤‘ì…ë‹ˆë‹¤ (60ì´ˆ)';
      case 'processing':
        return 'â³ AIê°€ ë‹µë³€ì„ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤...';
      case 'waiting_next':
        return 'âœ… ë…¹ìŒ ì™„ë£Œ! "ë‹¤ìŒ ì§ˆë¬¸" ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”';
      default:
        return '';
    }
  };

  return (
    <div className="min-h-screen bg-black text-white flex flex-col">
      {/* Header */}
      <header className="border-b border-gray-800 p-4 bg-gray-900/50">
        <div className="max-w-7xl mx-auto flex items-center justify-between">
          <h1 className="text-xl font-bold">AI ëª¨ì˜ ë©´ì ‘</h1>
          
          {/* ë©´ì ‘ ì¢…ë£Œ ë° ê²°ê³¼ ë³´ê¸° ë²„íŠ¼ */}
          <button
            onClick={handleFinishAndViewResults}
            disabled={turnNumber < 2 || interviewState === 'processing'}
            className={`px-6 py-2.5 rounded-lg transition-all duration-200 text-sm font-bold flex items-center gap-2 shadow-lg ${
              turnNumber < 2 || interviewState === 'processing'
                ? 'bg-gray-700 text-gray-500 cursor-not-allowed opacity-50'
                : 'bg-gradient-to-r from-primary-600 to-purple-600 hover:from-primary-700 hover:to-purple-700 text-white transform hover:scale-105'
            }`}
            title={
              turnNumber < 2 
                ? 'ìµœì†Œ 1ê°œ ì´ìƒì˜ ì§ˆë¬¸ì— ë‹µë³€í•´ì•¼ ê²°ê³¼ë¥¼ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤' 
                : 'í˜„ì¬ê¹Œì§€ì˜ ë‹µë³€ìœ¼ë¡œ AI í‰ê°€ë¥¼ ë°›ê³  ê²°ê³¼ë¥¼ í™•ì¸í•©ë‹ˆë‹¤'
            }
          >
            <svg className="w-5 h-5" fill="none" stroke="currentColor" viewBox="0 0 24 24">
              <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M9 5H7a2 2 0 00-2 2v12a2 2 0 002 2h10a2 2 0 002-2V7a2 2 0 00-2-2h-2M9 5a2 2 0 002 2h2a2 2 0 002-2M9 5a2 2 0 012-2h2a2 2 0 012 2m-6 9l2 2 4-4" />
            </svg>
            ë©´ì ‘ ì¢…ë£Œ ë° ê²°ê³¼ ë³´ê¸°
          </button>
        </div>
      </header>

      {/* Main Content */}
      <main className="flex-1 flex flex-col items-center justify-center p-8">
        <div className="max-w-4xl w-full space-y-8">
          {/* ì§„í–‰ ìƒíƒœ */}
          <div className="text-center space-y-2">
            <span className="text-2xl font-bold text-primary-500">ì§ˆë¬¸ {turnNumber} / 5</span>
            <p className="text-gray-400 text-sm">{getStateMessage()}</p>
          </div>

          {/* ì§ˆë¬¸ ì˜ì—­ */}
          <div className="p-8 bg-gradient-to-br from-gray-900 to-gray-800 rounded-2xl border-2 border-gray-700 min-h-[200px] flex items-center justify-center shadow-2xl">
            <p className="text-2xl text-center leading-relaxed font-medium">{questionText}</p>
          </div>

          {/* ìˆ¨ê²¨ì§„ ì˜¤ë””ì˜¤ í”Œë ˆì´ì–´ (TTS ìë™ ì¬ìƒ) */}
          <audio
            ref={audioRef}
            playsInline // ëª¨ë°”ì¼ì—ì„œ ì „ì²´í™”ë©´ ë°©ì§€
            muted={false} // ë³¼ë¥¨ ì²´í¬: ìŒì†Œê±° ì•ˆ ë¨
            preload="auto" // ë¯¸ë¦¬ ë¡œë“œ
            crossOrigin="anonymous" // CORS ì§€ì›
            onEnded={() => {
              console.log('ğŸ [TTS DEBUG] Audio playback ended');
              handleQuestionAudioEnded();
            }}
            onPlay={() => {
              console.log('âœ… [TTS DEBUG] Audio started playing');
              setShowPlayButton(false);
            }}
            onPause={() => console.log('â¸ï¸ [TTS DEBUG] Audio paused')}
            onError={(e) => {
              console.error('âŒ [TTS DEBUG] Audio load error:', e);
              const audio = e.currentTarget;
              console.error('[TTS DEBUG] Error code:', audio.error?.code);
              console.error('[TTS DEBUG] Error message:', audio.error?.message);
              console.error('[TTS DEBUG] Audio src:', audio.src);
              console.error('[TTS DEBUG] Network state:', audio.networkState);
              console.error('[TTS DEBUG] Ready state:', audio.readyState);
              setShowPlayButton(true); // ì—ëŸ¬ ì‹œ ìˆ˜ë™ ë²„íŠ¼ í‘œì‹œ
            }}
            onLoadedData={() => console.log('ğŸ“¥ [TTS DEBUG] Audio data loaded')}
            onCanPlay={() => console.log('âœ… [TTS DEBUG] Audio can play now')}
            onLoadStart={() => console.log('ğŸ”„ [TTS DEBUG] Audio load started')}
            onSuspend={() => console.log('â¸ï¸ [TTS DEBUG] Audio load suspended')}
            onStalled={() => console.log('âš ï¸ [TTS DEBUG] Audio load stalled')}
            className="hidden"
          >
            {/* source íƒœê·¸ë¡œ ëª…ì‹œì  MIME type ì§€ì • */}
            <source src={questionAudioUrl} type="audio/mpeg" />
            {/* í´ë°± ë©”ì‹œì§€ */}
            Your browser does not support the audio element.
          </audio>

          {/* ë…¹ìŒ ìƒíƒœ í‘œì‹œ */}
          {interviewState === 'recording' && (
            <div className="flex flex-col items-center gap-6">
              <CountdownTimer 
                duration={60} 
                isActive={true} 
                onComplete={handleCountdownComplete} 
              />
              <AudioVisualizer isRecording={true} />
              <button
                onClick={stopRecording}
                className="px-8 py-3 bg-red-600 hover:bg-red-700 rounded-lg transition-colors font-semibold shadow-lg"
              >
                ë…¹ìŒ ì¤‘ì§€
              </button>
            </div>
          )}

          {/* ë‹¤ìŒ ì§ˆë¬¸ ëŒ€ê¸° ìƒíƒœ */}
          {interviewState === 'waiting_next' && (
            <div className="flex flex-col items-center gap-4">
              <div className="text-center">
                <div className="w-20 h-20 mx-auto mb-4 rounded-full bg-green-600/20 flex items-center justify-center">
                  <svg className="w-10 h-10 text-green-500" fill="currentColor" viewBox="0 0 20 20">
                    <path fillRule="evenodd" d="M16.707 5.293a1 1 0 010 1.414l-8 8a1 1 0 01-1.414 0l-4-4a1 1 0 011.414-1.414L8 12.586l7.293-7.293a1 1 0 011.414 0z" clipRule="evenodd" />
                  </svg>
                </div>
                <p className="text-xl font-semibold text-green-400 mb-2">ë‹µë³€ ë…¹ìŒ ì™„ë£Œ!</p>
                <p className="text-gray-400 text-sm">ë‹¤ìŒ ì§ˆë¬¸ìœ¼ë¡œ ë„˜ì–´ê°€ì‹œë ¤ë©´ ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”</p>
              </div>
              
              {turnNumber < 5 ? (
                <button
                  onClick={handleNextQuestion}
                  className="px-12 py-4 bg-primary-600 hover:bg-primary-700 rounded-lg transition-colors font-bold text-lg shadow-xl"
                >
                  ë‹¤ìŒ ì§ˆë¬¸ â†’
                </button>
              ) : (
                <button
                  onClick={handleNextQuestion}
                  className="px-12 py-4 bg-green-600 hover:bg-green-700 rounded-lg transition-colors font-bold text-lg shadow-xl"
                >
                  ë©´ì ‘ ê²°ê³¼ ë³´ê¸° âœ“
                </button>
              )}
            </div>
          )}

          {/* ì²˜ë¦¬ ì¤‘ í‘œì‹œ */}
          {interviewState === 'processing' && (
            <div className="text-center">
              <div className="inline-block animate-spin rounded-full h-16 w-16 border-4 border-primary-500 border-t-transparent mb-6" />
              <p className="text-2xl font-bold text-primary-400 mb-3">ê²°ê³¼ ë¶„ì„ ì¤‘...</p>
              <p className="text-lg text-gray-300 mb-2">AIê°€ ë‹µë³€ì„ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤</p>
              <p className="text-sm text-gray-500">ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”. ê³§ ìƒì„¸í•œ í”¼ë“œë°±ì„ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p>
            </div>
          )}

          {/* ì²­ì·¨ ì¤‘ í‘œì‹œ */}
          {interviewState === 'listening' && (
            <div className="text-center">
              {showPlayButton ? (
                // ìë™ ì¬ìƒ ì‹¤íŒ¨ ì‹œ ìˆ˜ë™ ì¬ìƒ ë²„íŠ¼ í‘œì‹œ (í´ë°±)
                <div>
                  <div className="mb-6">
                    <div className="w-20 h-20 mx-auto mb-4 rounded-full bg-yellow-600/20 flex items-center justify-center">
                      <svg className="w-10 h-10 text-yellow-500" fill="currentColor" viewBox="0 0 20 20">
                        <path fillRule="evenodd" d="M18 10a8 8 0 11-16 0 8 8 0 0116 0zm-7-4a1 1 0 11-2 0 1 1 0 012 0zM9 9a1 1 0 000 2v3a1 1 0 001 1h1a1 1 0 100-2v-3a1 1 0 00-1-1H9z" clipRule="evenodd" />
                      </svg>
                    </div>
                    <p className="text-xl text-yellow-400 mb-2">ğŸ”Š ì§ˆë¬¸ ë“£ê¸°</p>
                    <p className="text-sm text-gray-400 mb-6">
                      ë¸Œë¼ìš°ì € ì„¤ì •ìœ¼ë¡œ ì¸í•´ ìë™ ì¬ìƒì´ ì°¨ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.<br />
                      ì•„ë˜ ë²„íŠ¼ì„ í´ë¦­í•˜ì—¬ ì§ˆë¬¸ì„ ë“¤ì–´ì£¼ì„¸ìš”.
                    </p>
                  </div>
                  <button
                    onClick={handleManualPlay}
                    className="px-12 py-4 bg-primary-600 hover:bg-primary-700 rounded-lg transition-colors font-bold text-lg shadow-xl flex items-center gap-3 mx-auto"
                  >
                    <svg className="w-6 h-6" fill="currentColor" viewBox="0 0 20 20">
                      <path fillRule="evenodd" d="M10 18a8 8 0 100-16 8 8 0 000 16zM9.555 7.168A1 1 0 008 8v4a1 1 0 001.555.832l3-2a1 1 0 000-1.664l-3-2z" clipRule="evenodd" />
                    </svg>
                    ğŸ”Š ì§ˆë¬¸ ë“£ê¸°
                  </button>
                </div>
              ) : (
                // ì •ìƒ ì¬ìƒ ì¤‘
                <div>
                  <div className="inline-block mb-4">
                    <div className="flex items-center gap-2">
                      <div className="w-3 h-3 bg-primary-500 rounded-full animate-pulse" style={{ animationDelay: '0ms' }} />
                      <div className="w-3 h-3 bg-primary-500 rounded-full animate-pulse" style={{ animationDelay: '150ms' }} />
                      <div className="w-3 h-3 bg-primary-500 rounded-full animate-pulse" style={{ animationDelay: '300ms' }} />
                    </div>
                  </div>
                  <p className="text-gray-400">ì§ˆë¬¸ì„ ì¬ìƒ ì¤‘ì…ë‹ˆë‹¤...</p>
                  <p className="text-xs text-gray-500 mt-2">ì¬ìƒì´ ì™„ë£Œë˜ë©´ ìë™ìœ¼ë¡œ ë…¹ìŒì´ ì‹œì‘ë©ë‹ˆë‹¤</p>
                </div>
              )}
            </div>
          )}
        </div>
      </main>
    </div>
  );
}


